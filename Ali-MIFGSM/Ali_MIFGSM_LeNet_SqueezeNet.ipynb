{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L0WcS-ITPOV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0a08860a-5f13-4361-b133-593ebee8c1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (4.67.1)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.12/dist-packages (from torchattacks) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.25.1->torchattacks) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchattacks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Small Models + MIFGSM Robust Training (LeNet & SqueezeNet on MNIST)\n",
        "\n",
        "This notebook trains:\n",
        "- Clean LeNet-5 and SqueezeNet on MNIST\n",
        "- MIFGSM-robust LeNet-5 and SqueezeNet using adversarial training\n",
        "\n",
        "It produces the following checkpoints in `models/`:\n",
        "- `lenet5_mnist_clean.pth`\n",
        "- `lenet5_mnist_robust_mifgsm.pth`\n",
        "- `squeezenet_mnist_clean.pth`\n",
        "- `squeezenet_mnist_robust_mifgsm.pth`"
      ],
      "metadata": {
        "id": "2lpaee81QXvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import squeezenet1_0\n",
        "\n",
        "from torchattacks import MIFGSM\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "-BFAtwvqQRk7",
        "outputId": "e86fd32e-d09d-47a6-cd9d-64f257b39264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_loaders(batch_size=64):\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=\"./MNISTData\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    test_dataset = datasets.MNIST(\n",
        "        root=\"./MNISTData\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
        "print(\"Train batches:\", len(train_loader), \"Test batches:\", len(test_loader))"
      ],
      "metadata": {
        "id": "CvZT70dzQdV5",
        "outputId": "e776118f-3062-4e7a-ed7c-2e1d1ed44d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 938 Test batches: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture is the same as listed in \"Small_Model_Training.ipynb\"\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=0)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SqueezeNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SqueezeNetMNIST, self).__init__()\n",
        "        base_model = squeezenet1_0(weights=None)\n",
        "        base_model.classifier[1] = nn.Conv2d(512, 10, kernel_size=1)\n",
        "        self.model = base_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "mxVq29zsQgpK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_clean(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "\n",
        "def train_clean(model, train_loader, test_loader,\n",
        "                epochs=10, lr=1e-2, save_path=None, device=device):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * y.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = 100.0 * correct / total\n",
        "        test_acc = evaluate_clean(model, test_loader, device)\n",
        "\n",
        "        print(f\"[CLEAN] Epoch {epoch:2d}/{epochs}: \"\n",
        "              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.2f}%, \"\n",
        "              f\"test_acc={test_acc:.2f}%\")\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(\"Saved clean model to:\", save_path)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "a2MoecOmQsLh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Clean LeNet\n",
        "lenet_clean = train_clean(\n",
        "    LeNet5(),\n",
        "    train_loader, test_loader,\n",
        "    epochs=10,\n",
        "    lr=1e-2,\n",
        "    save_path=\"models/lenet5_mnist_clean.pth\"\n",
        ")\n",
        "\n",
        "# 2) Clean SqueezeNet\n",
        "squeeze_clean = train_clean(\n",
        "    SqueezeNetMNIST(),\n",
        "    train_loader, test_loader,\n",
        "    epochs=10,\n",
        "    lr=1e-3,\n",
        "    save_path=\"models/squeezenet_mnist_clean.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "KU3m2N88QwMu",
        "outputId": "237d93aa-52d9-4ce8-86ed-b9ccbddc6d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEAN] Epoch  1/10: train_loss=0.4587, train_acc=85.00%, test_acc=97.46%\n",
            "[CLEAN] Epoch  2/10: train_loss=0.0822, train_acc=97.43%, test_acc=97.88%\n",
            "[CLEAN] Epoch  3/10: train_loss=0.0589, train_acc=98.15%, test_acc=98.11%\n",
            "[CLEAN] Epoch  4/10: train_loss=0.0480, train_acc=98.48%, test_acc=98.54%\n",
            "[CLEAN] Epoch  5/10: train_loss=0.0373, train_acc=98.82%, test_acc=98.87%\n",
            "[CLEAN] Epoch  6/10: train_loss=0.0323, train_acc=98.97%, test_acc=98.82%\n",
            "[CLEAN] Epoch  7/10: train_loss=0.0273, train_acc=99.10%, test_acc=98.77%\n",
            "[CLEAN] Epoch  8/10: train_loss=0.0238, train_acc=99.21%, test_acc=98.96%\n",
            "[CLEAN] Epoch  9/10: train_loss=0.0206, train_acc=99.34%, test_acc=98.94%\n",
            "[CLEAN] Epoch 10/10: train_loss=0.0176, train_acc=99.43%, test_acc=98.97%\n",
            "Saved clean model to: models/lenet5_mnist_clean.pth\n",
            "[CLEAN] Epoch  1/10: train_loss=0.7735, train_acc=74.20%, test_acc=95.93%\n",
            "[CLEAN] Epoch  2/10: train_loss=0.1501, train_acc=95.69%, test_acc=97.62%\n",
            "[CLEAN] Epoch  3/10: train_loss=0.1077, train_acc=96.84%, test_acc=97.26%\n",
            "[CLEAN] Epoch  4/10: train_loss=0.0846, train_acc=97.53%, test_acc=98.22%\n",
            "[CLEAN] Epoch  5/10: train_loss=0.0730, train_acc=97.84%, test_acc=98.15%\n",
            "[CLEAN] Epoch  6/10: train_loss=0.0636, train_acc=98.17%, test_acc=98.52%\n",
            "[CLEAN] Epoch  7/10: train_loss=0.0515, train_acc=98.53%, test_acc=98.48%\n",
            "[CLEAN] Epoch  8/10: train_loss=0.0492, train_acc=98.55%, test_acc=98.74%\n",
            "[CLEAN] Epoch  9/10: train_loss=0.0438, train_acc=98.69%, test_acc=98.57%\n",
            "[CLEAN] Epoch 10/10: train_loss=0.0401, train_acc=98.83%, test_acc=98.61%\n",
            "Saved clean model to: models/squeezenet_mnist_clean.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchattacks import MIFGSM\n",
        "\n",
        "def train_mifgsm_robust(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=10,\n",
        "    lr=1e-3,\n",
        "    eps=0.3,\n",
        "    steps=7,\n",
        "    decay=1.0,\n",
        "    device=None,\n",
        "    model_name=\"lenet5\"\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Using MIFGSM robust training (clean + adversarial per batch)\")\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "\n",
        "        # one attack object per epoch\n",
        "        atk = MIFGSM(model, eps=eps, steps=steps, decay=decay)\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # generate adversarial examples with model in eval mode\n",
        "            model.eval()\n",
        "            x_adv = atk(x, y)\n",
        "            model.train()\n",
        "\n",
        "            # combine clean + adversarial\n",
        "            train_images = torch.cat([x, x_adv.detach()], dim=0)\n",
        "            train_labels = torch.cat([y, y], dim=0)\n",
        "\n",
        "            # standard training step on combined batch\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(train_images)\n",
        "            loss = criterion(logits, train_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * train_labels.size(0)\n",
        "            total += train_labels.size(0)\n",
        "\n",
        "        avg_loss = running_loss / total\n",
        "\n",
        "        # evaluate on clean test set only (for logging)\n",
        "        model.eval()\n",
        "        correct_clean = 0\n",
        "        total_clean = 0\n",
        "        with torch.no_grad():\n",
        "            for x_test, y_test in test_loader:\n",
        "                x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "                logits_test = model(x_test)\n",
        "                preds_test = logits_test.argmax(1)\n",
        "                correct_clean += (preds_test == y_test).sum().item()\n",
        "                total_clean += y_test.size(0)\n",
        "        clean_acc = 100.0 * correct_clean / total_clean\n",
        "\n",
        "        print(\n",
        "            f\"[MIFGSM ROBUST] Epoch {epoch:2d}/{epochs}: \"\n",
        "            f\"train_loss={avg_loss:.4f}, clean_test_acc={clean_acc:.2f}%\"\n",
        "        )\n",
        "\n",
        "    # save checkpoint\n",
        "    save_name = f\"models/{model_name}_mnist_robust_mifgsm.pth\"\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    torch.save(model.state_dict(), save_name)\n",
        "    print(f\"Saved MIFGSM-robust model to: {save_name}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ywci3ZOWV8NR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
        "\n",
        "# LeNet robust\n",
        "lenet_robust = LeNet5()\n",
        "lenet_robust = train_mifgsm_robust(\n",
        "    lenet_robust,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=10,\n",
        "    lr=1e-3,\n",
        "    eps=0.3,\n",
        "    steps=7,\n",
        "    decay=1.0,\n",
        "    device=device,\n",
        "    model_name=\"lenet5\"\n",
        ")\n",
        "\n",
        "# SqueezeNet robust\n",
        "squeeze_robust = SqueezeNetMNIST()\n",
        "squeeze_robust = train_mifgsm_robust(\n",
        "    squeeze_robust,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=10,\n",
        "    lr=1e-3,\n",
        "    eps=0.3,\n",
        "    steps=7,\n",
        "    decay=1.0,\n",
        "    device=device,\n",
        "    model_name=\"squeezenet\"\n",
        ")"
      ],
      "metadata": {
        "id": "NhztonliV9xq",
        "outputId": "f80a5045-0eaa-47c7-958c-2f5513b55eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using MIFGSM robust training (clean + adversarial per batch)\n",
            "[MIFGSM ROBUST] Epoch  1/10: train_loss=0.4035, clean_test_acc=97.15%\n",
            "[MIFGSM ROBUST] Epoch  2/10: train_loss=0.1375, clean_test_acc=98.16%\n",
            "[MIFGSM ROBUST] Epoch  3/10: train_loss=0.1019, clean_test_acc=98.76%\n",
            "[MIFGSM ROBUST] Epoch  4/10: train_loss=0.0835, clean_test_acc=98.71%\n",
            "[MIFGSM ROBUST] Epoch  5/10: train_loss=0.0738, clean_test_acc=98.97%\n",
            "[MIFGSM ROBUST] Epoch  6/10: train_loss=0.0642, clean_test_acc=98.99%\n",
            "[MIFGSM ROBUST] Epoch  7/10: train_loss=0.0579, clean_test_acc=99.02%\n",
            "[MIFGSM ROBUST] Epoch  8/10: train_loss=0.0522, clean_test_acc=98.96%\n",
            "[MIFGSM ROBUST] Epoch  9/10: train_loss=0.0485, clean_test_acc=99.03%\n",
            "[MIFGSM ROBUST] Epoch 10/10: train_loss=0.0436, clean_test_acc=99.19%\n",
            "Saved MIFGSM-robust model to: models/lenet5_mnist_robust_mifgsm.pth\n",
            "Using MIFGSM robust training (clean + adversarial per batch)\n",
            "[MIFGSM ROBUST] Epoch  1/10: train_loss=0.9107, clean_test_acc=79.22%\n",
            "[MIFGSM ROBUST] Epoch  2/10: train_loss=0.5991, clean_test_acc=79.80%\n",
            "[MIFGSM ROBUST] Epoch  3/10: train_loss=0.5606, clean_test_acc=79.98%\n",
            "[MIFGSM ROBUST] Epoch  4/10: train_loss=0.5455, clean_test_acc=80.18%\n",
            "[MIFGSM ROBUST] Epoch  5/10: train_loss=0.5367, clean_test_acc=80.19%\n",
            "[MIFGSM ROBUST] Epoch  6/10: train_loss=0.5265, clean_test_acc=80.10%\n",
            "[MIFGSM ROBUST] Epoch  7/10: train_loss=0.5189, clean_test_acc=80.26%\n",
            "[MIFGSM ROBUST] Epoch  8/10: train_loss=0.5177, clean_test_acc=80.34%\n",
            "[MIFGSM ROBUST] Epoch  9/10: train_loss=0.5166, clean_test_acc=80.28%\n",
            "[MIFGSM ROBUST] Epoch 10/10: train_loss=0.5106, clean_test_acc=80.28%\n",
            "Saved MIFGSM-robust model to: models/squeezenet_mnist_robust_mifgsm.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mifgsm_dataset(model, data_loader, save_path,\n",
        "                            eps=0.3, steps=7, decay=1.0, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    atk = MIFGSM(model, eps=eps, steps=steps, decay=decay)\n",
        "\n",
        "    adv_images_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        x.requires_grad = True\n",
        "        adv_x = atk(x, y)\n",
        "        x.requires_grad = False\n",
        "\n",
        "        adv_images_list.append(adv_x.detach().cpu())\n",
        "        labels_list.append(y.detach().cpu())\n",
        "\n",
        "    adv_images = torch.cat(adv_images_list)\n",
        "    adv_labels = torch.cat(labels_list)\n",
        "\n",
        "    torch.save({\"image\": adv_images, \"label\": adv_labels}, save_path)\n",
        "    print(f\"Saved {adv_images.shape[0]} adversarial examples to {save_path}\")"
      ],
      "metadata": {
        "id": "VCkwDr0wuOtu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)  # same loader as before\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
        "\n",
        "# Load clean/robust LeNet\n",
        "lenet_clean = LeNet5().to(device)\n",
        "lenet_clean.load_state_dict(torch.load(\"models/lenet5_mnist_clean.pth\",\n",
        "                                       map_location=device))\n",
        "lenet_robust = LeNet5().to(device)\n",
        "lenet_robust.load_state_dict(torch.load(\"models/lenet5_mnist_robust_mifgsm.pth\",\n",
        "                                        map_location=device))\n",
        "\n",
        "# Generate MIFGSM adversarial sets on the *test* set for LeNet\n",
        "generate_mifgsm_dataset(\n",
        "    lenet_clean, test_loader,\n",
        "    \"adv_lenet_clean_mifgsm.pt\",\n",
        "    eps=0.3, steps=7, decay=1.0, device=device\n",
        ")\n",
        "\n",
        "generate_mifgsm_dataset(\n",
        "    lenet_robust, test_loader,\n",
        "    \"adv_lenet_robust_mifgsm.pt\",\n",
        "    eps=0.3, steps=7, decay=1.0, device=device\n",
        ")\n",
        "\n",
        "\n",
        "# Load clean/robust SqueezeNet\n",
        "squeeze_clean = SqueezeNetMNIST().to(device)\n",
        "squeeze_clean.load_state_dict(torch.load(\"models/squeezenet_mnist_clean.pth\", map_location=device))\n",
        "\n",
        "squeeze_robust = SqueezeNetMNIST().to(device)\n",
        "squeeze_robust.load_state_dict(torch.load(\"models/squeezenet_mnist_robust_mifgsm.pth\", map_location=device))\n",
        "\n",
        "# Generate MIFGSM adversarial sets on the *test* set\n",
        "generate_mifgsm_dataset(\n",
        "    squeeze_clean, test_loader,\n",
        "    \"adv_squeezenet_clean_mifgsm.pt\",\n",
        "    eps=0.3, steps=7, decay=1.0, device=device\n",
        ")\n",
        "\n",
        "generate_mifgsm_dataset(\n",
        "    squeeze_robust, test_loader,\n",
        "    \"adv_squeezenet_robust_mifgsm.pt\",\n",
        "    eps=0.3, steps=7, decay=1.0, device=device\n",
        ")"
      ],
      "metadata": {
        "id": "X1LIqhFkWpaT",
        "outputId": "c13743ed-066d-4d5d-8976-87681e399881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 10000 adversarial examples to adv_lenet_clean_mifgsm.pt\n",
            "Saved 10000 adversarial examples to adv_lenet_robust_mifgsm.pt\n",
            "Saved 10000 adversarial examples to adv_squeezenet_clean_mifgsm.pt\n",
            "Saved 10000 adversarial examples to adv_squeezenet_robust_mifgsm.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_on_adv(model, adv_dict, device):\n",
        "    model.eval()\n",
        "    x = adv_dict[\"image\"].to(device)\n",
        "    y = adv_dict[\"label\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(1)\n",
        "        acc = (preds == y).float().mean().item() * 100\n",
        "    return acc\n",
        "\n",
        "lenet_clean_adv = torch.load(\"adv_lenet_clean_mifgsm.pt\")\n",
        "lenet_rob_adv   = torch.load(\"adv_lenet_robust_mifgsm.pt\")\n",
        "\n",
        "acc_lenet_clean_on_own = eval_on_adv(lenet_clean, lenet_clean_adv, device)\n",
        "acc_lenet_rob_on_own   = eval_on_adv(lenet_robust, lenet_rob_adv, device)"
      ],
      "metadata": {
        "id": "ydZgWoRTWn2u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeeze_clean = SqueezeNetMNIST().to(device)\n",
        "squeeze_clean.load_state_dict(torch.load(\"models/squeezenet_mnist_clean.pth\", map_location=device))\n",
        "\n",
        "squeeze_robust = SqueezeNetMNIST().to(device)\n",
        "squeeze_robust.load_state_dict(torch.load(\"models/squeezenet_mnist_robust_mifgsm.pth\", map_location=device))\n",
        "\n",
        "squeeze_clean_adv = torch.load(\"adv_squeezenet_clean_mifgsm.pt\")\n",
        "squeeze_rob_adv   = torch.load(\"adv_squeezenet_robust_mifgsm.pt\")\n",
        "\n",
        "# Example: LeNet robust on SqueezeNet's attack\n",
        "acc_lenet_rob_on_sq_clean_adv = eval_on_adv(lenet_robust, squeeze_clean_adv, device)"
      ],
      "metadata": {
        "id": "MCFn31YLXb2T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_clean_acc(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100.0 * correct / total"
      ],
      "metadata": {
        "id": "zeK5K2LuYOPf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
        "\n",
        "lenet_clean = LeNet5().to(device)\n",
        "lenet_clean.load_state_dict(torch.load(\"models/lenet5_mnist_clean.pth\", map_location=device))\n",
        "\n",
        "lenet_robust = LeNet5().to(device)\n",
        "lenet_robust.load_state_dict(torch.load(\"models/lenet5_mnist_robust_mifgsm.pth\", map_location=device))\n",
        "\n",
        "squeeze_clean = SqueezeNetMNIST().to(device)\n",
        "squeeze_clean.load_state_dict(torch.load(\"models/squeezenet_mnist_clean.pth\", map_location=device))\n",
        "\n",
        "squeeze_robust = SqueezeNetMNIST().to(device)\n",
        "squeeze_robust.load_state_dict(torch.load(\"models/squeezenet_mnist_robust_mifgsm.pth\", map_location=device))\n",
        "\n",
        "# Load adversarial sets\n",
        "lenet_clean_adv = torch.load(\"adv_lenet_clean_mifgsm.pt\")\n",
        "lenet_rob_adv   = torch.load(\"adv_lenet_robust_mifgsm.pt\")\n",
        "squeeze_clean_adv = torch.load(\"adv_squeezenet_clean_mifgsm.pt\")\n",
        "squeeze_rob_adv   = torch.load(\"adv_squeezenet_robust_mifgsm.pt\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Clean accuracies\n",
        "results[(\"LeNet clean\", \"Clean test\")]      = eval_clean_acc(lenet_clean, test_loader, device)\n",
        "results[(\"LeNet robust\", \"Clean test\")]     = eval_clean_acc(lenet_robust, test_loader, device)\n",
        "results[(\"SqNet clean\", \"Clean test\")]      = eval_clean_acc(squeeze_clean, test_loader, device)\n",
        "results[(\"SqNet robust\", \"Clean test\")]     = eval_clean_acc(squeeze_robust, test_loader, device)\n",
        "\n",
        "# Own-attack MIFGSM accuracies (white-box)\n",
        "results[(\"LeNet clean\", \"MIFGSM (LeNet clean)\")]  = eval_on_adv(lenet_clean,  lenet_clean_adv, device)\n",
        "results[(\"LeNet robust\", \"MIFGSM (LeNet robust)\")] = eval_on_adv(lenet_robust, lenet_rob_adv, device)\n",
        "results[(\"SqNet clean\", \"MIFGSM (SqNet clean)\")]  = eval_on_adv(squeeze_clean,  squeeze_clean_adv, device)\n",
        "results[(\"SqNet robust\", \"MIFGSM (SqNet robust)\")] = eval_on_adv(squeeze_robust, squeeze_rob_adv, device)\n",
        "\n",
        "# Cross-transfer: LeNet <-> SqueezeNet\n",
        "results[(\"LeNet clean\", \"MIFGSM (SqNet clean)\")]   = eval_on_adv(lenet_clean,  squeeze_clean_adv, device)\n",
        "results[(\"LeNet robust\", \"MIFGSM (SqNet clean)\")]  = eval_on_adv(lenet_robust, squeeze_clean_adv, device)\n",
        "results[(\"SqNet clean\", \"MIFGSM (LeNet clean)\")]   = eval_on_adv(squeeze_clean,  lenet_clean_adv, device)\n",
        "results[(\"SqNet robust\", \"MIFGSM (LeNet clean)\")]  = eval_on_adv(squeeze_robust, lenet_clean_adv, device)\n",
        "\n",
        "for (model_name, eval_case), acc in results.items():\n",
        "    print(f\"{model_name:12s} on {eval_case:26s}: {acc:5.2f}%\")"
      ],
      "metadata": {
        "id": "h7cvtnEsYQwR",
        "outputId": "39e97061-e46a-474a-ba2b-1ecaed3ee8ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet clean  on Clean test                : 98.97%\n",
            "LeNet robust on Clean test                : 99.19%\n",
            "SqNet clean  on Clean test                : 98.61%\n",
            "SqNet robust on Clean test                : 80.28%\n",
            "LeNet clean  on MIFGSM (LeNet clean)      : 92.94%\n",
            "LeNet robust on MIFGSM (LeNet robust)     : 97.07%\n",
            "SqNet clean  on MIFGSM (SqNet clean)      : 83.14%\n",
            "SqNet robust on MIFGSM (SqNet robust)     : 78.60%\n",
            "LeNet clean  on MIFGSM (SqNet clean)      : 98.41%\n",
            "LeNet robust on MIFGSM (SqNet clean)      : 98.82%\n",
            "SqNet clean  on MIFGSM (LeNet clean)      : 97.11%\n",
            "SqNet robust on MIFGSM (LeNet clean)      : 79.82%\n"
          ]
        }
      ]
    }
  ]
}