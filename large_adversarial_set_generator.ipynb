{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ec623b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ec623b",
        "outputId": "20c43fb9-7dc5-4d54-e116-03f612b5a1b5",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install torchattack > /dev/null\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as DataUtils\n",
        "from torchvision.models import squeezenet1_0\n",
        "from torchattack import PGD\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbaccaa",
      "metadata": {
        "id": "8bbaccaa",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=0)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class SqueezeNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SqueezeNetMNIST, self).__init__()\n",
        "        self.model = squeezenet1_0(num_classes=10)\n",
        "        self.model.features[0] = nn.Conv2d(1, 96, kernel_size=7, stride=2)\n",
        "        self.model.classifier[1] = nn.Conv2d(512, 10, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4181859",
      "metadata": {
        "id": "a4181859",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def get_dataloader(train=False, batch_size=64):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dset = datasets.MNIST(root='./data', train=train, download=True, transform=transform)\n",
        "    return DataUtils.DataLoader(dset, batch_size=batch_size, shuffle=train)\n",
        "\n",
        "def train_proxy_model(arch, epochs=2):\n",
        "    print(f\"Training Proxy {arch}...\")\n",
        "    model = LeNet5().to(device) if arch == 'lenet' else SqueezeNetMNIST().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    train_loader = get_dataloader(train=True)\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for imgs, lbls in train_loader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, lbls)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e8c54d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e8c54d",
        "outputId": "166b05ce-3621-4a6a-cfbe-cbebe47ce58e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing resnet18_pgd_robust.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 5.0648\n",
            "\n",
            "Processing resnet18_standard_trained.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.4346\n",
            "\n",
            "Processing resnet50_pgd_robust.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.8592\n",
            "\n",
            "Processing resnet50_standard_trained.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.2504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_path = '/content/drive/My Drive/adversarial_mnist'\n",
        "dirs = {\n",
        "    'weights': f'{base_path}/model_weights',\n",
        "    'std_adv': f'{base_path}/large_adversarial_examples',\n",
        "    'proxy_adv': f'{base_path}/proxy_adversarial_examples'\n",
        "}\n",
        "for d in dirs.values(): os.makedirs(d, exist_ok=True)\n",
        "\n",
        "target_models = [\n",
        "    ('lenet', 'lenet.pth'),\n",
        "    ('lenet', 'lenet_robust.pth'),\n",
        "    ('squeezenet', 'squeezenet.pth'),\n",
        "    ('squeezenet', 'squeezenet_robust.pth')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89f7dd86",
      "metadata": {
        "id": "89f7dd86",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "loader = get_dataloader(train=False, batch_size=32)\n",
        "\n",
        "print(\"\\n--- Generating Standard Attacks (Source = Target) ---\")\n",
        "for arch, filename in target_models:\n",
        "    print(f\"Processing {filename}...\")\n",
        "    model = LeNet5().to(device) if 'lenet' in arch else SqueezeNetMNIST().to(device)\n",
        "    model.load_state_dict(torch.load(f\"{dirs['weights']}/{filename}\", map_location=device))\n",
        "    model.eval()\n",
        "    \n",
        "    adversary = PGD(model, eps=0.3, steps=40, random_start=True)\n",
        "    \n",
        "    examples, true_lbls, fooled_lbls, dists = [], [], [], []\n",
        "    total, fooled = 0, 0\n",
        "    \n",
        "    for img, lbl in loader:\n",
        "        if len(examples) >= 500: break\n",
        "        img, lbl = img.to(device), lbl.to(device)\n",
        "        adv = adversary(img, lbl)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            pred = model(adv).argmax(1)\n",
        "        \n",
        "        batch_fool = (pred != lbl)\n",
        "        total += len(lbl)\n",
        "        fooled += batch_fool.sum().item()\n",
        "        \n",
        "        if batch_fool.sum() > 0:\n",
        "            diff = (adv - img).reshape(len(img), -1)\n",
        "            l2 = torch.norm(diff, p=2, dim=1)\n",
        "            \n",
        "            examples.append(adv[batch_fool].cpu())\n",
        "            true_lbls.append(lbl[batch_fool].cpu())\n",
        "            fooled_lbls.append(pred[batch_fool].cpu())\n",
        "            dists.append(l2[batch_fool].cpu())\n",
        "\n",
        "    rob_acc = 100 * (1 - fooled/total)\n",
        "    avg_dist = torch.cat(dists).mean().item() if dists else 0\n",
        "    \n",
        "    torch.save({\n",
        "        'adv': torch.cat(examples)[:500], 'lbl': torch.cat(true_lbls)[:500],\n",
        "        'metrics': {'robustness': rob_acc, 'avg_l2': avg_dist}\n",
        "    }, f\"{dirs['std_adv']}/500_adv_{filename}\")\n",
        "    print(f\"  Robustness: {rob_acc:.2f}%, Avg L2: {avg_dist:.4f}\")\n",
        "\n",
        "print(\"\\n--- Generating Proxy Attacks (Source = Proxy) ---\")\n",
        "proxies = {\n",
        "    'lenet': train_proxy_model('lenet'),\n",
        "    'squeezenet': train_proxy_model('squeezenet')\n",
        "}\n",
        "\n",
        "for arch, _ in target_models:\n",
        "    proxy_model = proxies[arch]\n",
        "    adversary = PGD(proxy_model, eps=0.3, steps=40, random_start=True)\n",
        "    \n",
        "    examples, true_lbls = [], []\n",
        "    \n",
        "    for img, lbl in loader:\n",
        "        if len(examples) >= 500: break\n",
        "        img, lbl = img.to(device), lbl.to(device)\n",
        "        adv = adversary(img, lbl)\n",
        "        \n",
        "        examples.append(adv.cpu())\n",
        "        true_lbls.append(lbl.cpu())\n",
        "\n",
        "    torch.save({\n",
        "        'adv': torch.cat(examples)[:500], \n",
        "        'lbl': torch.cat(true_lbls)[:500]\n",
        "    }, f\"{dirs['proxy_adv']}/proxy_adv_{arch}_for_transfer.pth\")\n",
        "    print(f\"  Saved proxy attacks for {arch}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
