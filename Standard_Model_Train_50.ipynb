{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vm2781/adversarial_attacks/blob/main/Standard_Model_Train_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKs70YDzokox"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.utils.data as DataUtils\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Readymade data loading function\n",
        "DATA_ROOT='./MNISTData/'\n",
        "def getMNISTDataLoaders(batchSize=64, nTrain=50000, nVal=10000, nTest=10000):\n",
        "  # You can use technically use the same transform instance for all 3 sets\n",
        "  assert (60000 - nVal) == nTrain, 'nTrain + nVal must be equal to 60000'\n",
        "  trainTransform = transforms.Compose([transforms.ToTensor()])\n",
        "  valTransform = transforms.Compose([transforms.ToTensor()])\n",
        "  testTransform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  trainSet = datasets.MNIST(root=DATA_ROOT, download=True, train=True, \\\n",
        "                           transform=trainTransform)\n",
        "  valSet = datasets.MNIST(root=DATA_ROOT, download=True, train=True, \\\n",
        "                         transform=valTransform)\n",
        "  testSet = datasets.MNIST(root=DATA_ROOT, download=True, train=False, \\\n",
        "                                 transform=testTransform)\n",
        "\n",
        "  indices = np.arange(0, 60000)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  trainSampler = SubsetRandomSampler(indices[:nTrain])\n",
        "  valSampler = SubsetRandomSampler(indices[nTrain:])\n",
        "  testSampler = SubsetRandomSampler(np.arange(0, nTest))\n",
        "\n",
        "  trainLoader = DataUtils.DataLoader(trainSet, batch_size=batchSize, \\\n",
        "                                   sampler=trainSampler)\n",
        "  valLoader = DataUtils.DataLoader(valSet, batch_size=batchSize, \\\n",
        "                                  sampler=valSampler)\n",
        "  testLoader = DataUtils.DataLoader(testSet, batch_size=batchSize, \\\n",
        "                                    sampler=testSampler)\n",
        "  return trainLoader, valLoader, testLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2Glc_6forVe"
      },
      "outputs": [],
      "source": [
        "# Define the `device` PyTorch will be running on\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Notebook will use PyTorch Device: ' + device.upper())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdMul1H8ov0X"
      },
      "outputs": [],
      "source": [
        "# Utility Progress Bar Function\n",
        "def progress(curr, total, suffix=''):\n",
        "  bar_len = 48\n",
        "  filled = int(round(bar_len * curr / float(total)))\n",
        "  if filled == 0:\n",
        "    filled = 1\n",
        "  bar = '=' * (filled - 1) + '>' + '-' * (bar_len - filled)\n",
        "  sys.stdout.write('\\r[%s] .. %s' % (bar, suffix))\n",
        "  sys.stdout.flush()\n",
        "  if curr == total:\n",
        "    bar = bar_len * '='\n",
        "    sys.stdout.write('\\r[%s] .. %s .. Completed\\n' % (bar, suffix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKRdgIl4ozop"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "model = models.resnet50(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # (it defaults to 1000 classes for ImageNet, but we'll override below)\n",
        "model.fc = nn.Linear(512, 10)  # Ensure output is 10 classes for MNIST digits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6vYGr1go5LU"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_epochs = 10\n",
        "lr = 1e-2\n",
        "step = 0\n",
        "xent_loss = nn.CrossEntropyLoss()\n",
        "adv_model = adv_model.to(device)\n",
        "adv_model.train()\n",
        "optimizer = torch.optim.SGD(adv_model.parameters(), lr=lr)\n",
        "\n",
        "train_loader, val_loader, test_loader = getMNISTDataLoaders()\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NGDqi8ZpOwj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7djMh09mpSVd"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "robust_eval_dataset = torch.load(\"/content/drive/My Drive/adversarial_mnist/pgd_eval_dataset.pt\")\n",
        "images = robust_eval_dataset[\"images\"]      # shape: [N, C, H, W]\n",
        "labels = robust_eval_dataset[\"labels\"]      # shape: [N]\n",
        "\n",
        "class RobustDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        lbl = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, lbl\n",
        "\n",
        "robust_eval_dataset = RobustDataset(images, labels)\n",
        "robust_eval_dataloader = DataLoader(robust_eval_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FDcoKzspVKR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Modified adversarial training using torchattack library.\n",
        "Now trains on both original and adversarial examples for better robustness\n",
        "while maintaining clean accuracy.\n",
        "\"\"\"\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "validation_reg_accuracy = []\n",
        "validation_robust_accuracy = []\n",
        "for i in range(n_epochs):\n",
        "  for j, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = adv_model(images)\n",
        "    loss = loss_fn(logits, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if j % 8 == 0:\n",
        "      progress(j+1, len(train_loader), 'Batch [{}/{}] Epoch [{}/{}] Loss = {:.3f}'.format(j+1, len(train_loader), i+1, n_epochs, loss.item()))\n",
        "\n",
        "    step += 1\n",
        "  val_correct = 0\n",
        "  adv_model.eval()\n",
        "  for(j, (images, labels)) in enumerate(val_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    logits = adv_model(images)\n",
        "    _, preds = torch.max(logits, 1)\n",
        "    val_correct += (preds == labels).sum().item()\n",
        "    progress(j+1, len(val_loader), 'Batch [{}/{}]'.format(j+1, len(val_loader)))\n",
        "  print('Validation Accuracy = {}%'.format(float(val_correct) * 100 / 10000))\n",
        "  validation_reg_accuracy.append(float(val_correct) * 100 / 10000)\n",
        "\n",
        "  val_rob_correct = 0\n",
        "  adv_model.eval()\n",
        "  for(j, (images, labels)) in enumerate(robust_eval_dataloader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    logits = adv_model(images)\n",
        "    _, preds = torch.max(logits, 1)\n",
        "    val_rob_correct += (preds == labels).sum().item()\n",
        "    progress(j+1, len(robust_eval_dataset), 'Batch [{}/{}]'.format(j+1, len(robust_eval_dataset)))\n",
        "  print('Robust Validation Accuracy = {}%'.format(float(val_rob_correct) * 100 / 500))\n",
        "  validation_robust_accuracy.append(float(val_rob_correct) * 100 / 500)\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print('\\nTotal training steps = {}'.format(step))\n",
        "print('Total time taken = {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r1QlbcPpneU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Evaluation code - 98.92%\n",
        "correct = 0\n",
        "adv_model.eval()\n",
        "for j, (images, labels) in enumerate(test_loader):\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  logits = adv_model(images)\n",
        "  _, preds = torch.max(logits, 1)\n",
        "  correct += (preds == labels).sum().item()\n",
        "  progress(j+1, len(test_loader), 'Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
        "adv_model.train()\n",
        "print('Accuracy = {}%'.format(float(correct) * 100 / 10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgXpgJ2CpqIH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, n_epochs + 1), validation_reg_accuracy, label='Validation Accuracy', marker='o')\n",
        "plt.plot(range(1, n_epochs + 1), validation_robust_accuracy, label='Robust Evaluation Accuracy', marker='x')\n",
        "\n",
        "plt.title('ResNet50 - Standard : Validation Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(1, n_epochs + 1))\n",
        "save_path = \"/content/drive/My Drive/adversarial_mnist/resnet50_standard_new_trained.png\"\n",
        "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u40YXIEapwd0"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories in Google Drive\n",
        "#os.makedirs('/content/drive/My Drive/adversarial_mnist/all_saved_models', exist_ok=True)\n",
        "# os.makedirs('/content/drive/My Drive/adversarial_mnist/adversarial_examples', exist_ok=True)\n",
        "\n",
        "# Save the adversarially trained model\n",
        "torch.save(adv_model.state_dict(), '/content/drive/My Drive/adversarial_mnist/all_saved_models/resnet50_standard_trained.pth')\n",
        "print(\"Model saved to Google Drive: adversarial_mnist/saved_models/resnet50_standard_trained.pth\")\n",
        "\n",
        "print(\"\\nGoogle Drive structure created:\")\n",
        "print(\"  My Drive/\")\n",
        "print(\"    adversarial_mnist/\")\n",
        "print(\"      saved_models/\")\n",
        "print(\"      adversarial_examples/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzNo89iep503"
      },
      "outputs": [],
      "source": [
        "import torchattack\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "adv_model.eval()\n",
        "\n",
        "#os.makedirs('/content/drive/My Drive/adversarial_mnist/adversarial_examples', exist_ok=True)\n",
        "# We'll loop through the test set until we collect 25 fooling examples\n",
        "fooling_examples = []\n",
        "fooling_labels = []\n",
        "fooling_perturbations = []\n",
        "fooled_as_labels = []\n",
        "examples_found = 0\n",
        "target_count = 25\n",
        "\n",
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "    if examples_found >= target_count:\n",
        "        break\n",
        "\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Generate adversarial examples\n",
        "    adversary = torchattack.PGD(adv_model, eps=0.3, steps=7, random_start=True)\n",
        "    adv_images = adversary(images, labels)\n",
        "\n",
        "    # Get model predictions on adversarial examples\n",
        "    with torch.no_grad():\n",
        "        logits = adv_model(adv_images)\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "    # Find which ones actually fool the model (prediction != true label)\n",
        "    fooled_mask = (preds != labels)\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "        if examples_found >= target_count:\n",
        "            break\n",
        "\n",
        "        if fooled_mask[i].item():  # Only save if it fooled the model\n",
        "            clean_img = images[i].cpu().detach()\n",
        "            adv_img = adv_images[i].cpu().detach()\n",
        "            perturbation = (adv_img - clean_img).detach()\n",
        "\n",
        "            fooling_examples.append(adv_img)\n",
        "            fooling_labels.append(labels[i].item())\n",
        "            fooling_perturbations.append(perturbation)\n",
        "            fooled_as_labels.append(preds[i].item())\n",
        "\n",
        "            # Save individual examples as tensors to Google Drive\n",
        "            torch.save({\n",
        "                'clean': clean_img,\n",
        "                'adversarial': adv_img,\n",
        "                'perturbation': perturbation,\n",
        "                'true_label': labels[i].item(),\n",
        "                'fooled_label': preds[i].item()\n",
        "            }, f'/content/drive/My Drive/adversarial_mnist/adversarial_examples_resnet50/fooling_example_{examples_found}.pth')\n",
        "\n",
        "            # Save PNG visualizations\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
        "\n",
        "            # Clean image\n",
        "            axes[0].imshow(clean_img.squeeze().numpy(), cmap='gray')\n",
        "            axes[0].set_title(f'Clean\\nTrue Label: {labels[i].item()}')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # Adversarial image\n",
        "            axes[1].imshow(adv_img.squeeze().numpy(), cmap='gray')\n",
        "            axes[1].set_title(f'Adversarial\\nFooled as: {preds[i].item()}')\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            # Perturbation (amplified for visibility)\n",
        "            perturbation_vis = perturbation.squeeze().abs() * 10  # Scale for visibility\n",
        "            axes[2].imshow(perturbation_vis.numpy(), cmap='hot')\n",
        "            axes[2].set_title(f'Perturbation\\n(amplified)')\n",
        "            axes[2].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'/content/drive/My Drive/adversarial_mnist/adversarial_examples_resnet50/fooling_example_{examples_found}.png',\n",
        "                        dpi=100, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            examples_found += 1\n",
        "            print(f\"Found {examples_found}/25 fooling examples\")\n",
        "\n",
        "# Save all fooling examples as a single tensor file to Google Drive\n",
        "torch.save({\n",
        "    'adversarial_examples': torch.stack(fooling_examples),\n",
        "    'true_labels': fooling_labels,\n",
        "    'fooled_as_labels': fooled_as_labels,\n",
        "    'perturbations': torch.stack(fooling_perturbations)\n",
        "}, '/content/drive/My Drive/adversarial_mnist/adversarial_examples_resnet50/all_fooling_examples.pth')\n",
        "\n",
        "print(f\"\\nTotal fooling examples found: {examples_found}\")\n",
        "print(\"All files saved to Google Drive: My Drive/adversarial_mnist/\")\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"  - fooling_example_X.pth (tensor data)\")\n",
        "print(\"  - fooling_example_X.png (visualization)\")\n",
        "print(\"  - all_fooling_examples.pth (all examples combined)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNpYG5LUxvXI8oXz9Rwu/ol",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
