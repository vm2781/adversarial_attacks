{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a8666e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0a8666e",
        "outputId": "7af2aa95-9b89-4cf9-ff82-747d4d1780eb",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchvision.models import squeezenet1_0\n",
        "from google.colab import drive\n",
        "from torchattack import PGD\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733baa31",
      "metadata": {
        "id": "733baa31",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.flat(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "model_configs = [\n",
        "    ('Std LeNet', 'lenet.pth', 'lenet'),\n",
        "    ('Std Squeeze', 'squeezenet.pth', 'squeezenet'),\n",
        "    ('Rob LeNet', 'lenet_robust.pth', 'lenet'),\n",
        "    ('Rob Squeeze', 'squeezenet_robust.pth', 'squeezenet')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p7LFZHMgxomp",
      "metadata": {
        "id": "p7LFZHMgxomp"
      },
      "outputs": [],
      "source": [
        "def get_train_loader(batch_size=128):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    return torch.utils.data.DataLoader(dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def train_zoo_model(arch_cls, robust=False, epochs=3):\n",
        "    model = arch_cls().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loader = get_train_loader()\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for imgs, lbls in loader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            \n",
        "            if robust:\n",
        "                model.eval()\n",
        "                adv_imgs = PGD(model, eps=0.3, steps=3, alpha=0.1)(imgs, lbls)\n",
        "                model.train()\n",
        "                imgs = torch.cat([imgs, adv_imgs])\n",
        "                lbls = torch.cat([lbls, lbls])\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, lbls)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MIokrABNyPZt",
      "metadata": {
        "id": "MIokrABNyPZt"
      },
      "outputs": [],
      "source": [
        "print(\"Training Evaluation Zoo...\")\n",
        "zoo_models = {\n",
        "    'MLP_Std': train_zoo_model(SimpleMLP, robust=False),\n",
        "    'MLP_Rob': train_zoo_model(SimpleMLP, robust=True),\n",
        "    'CNN_Std': train_zoo_model(SimpleCNN, robust=False),\n",
        "    'CNN_Rob': train_zoo_model(SimpleCNN, robust=True),\n",
        "}\n",
        "print(\"Zoo Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HCt64VMgyhrO",
      "metadata": {
        "id": "HCt64VMgyhrO"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/drive/My Drive/adversarial_mnist'\n",
        "adv_dir = f'{base_path}/large_adversarial_examples'\n",
        "ext_data_path = f'{base_path}/external_dataset/mnist_fgsm_test.csv'\n",
        "\n",
        "ext_imgs, ext_lbls = None, None\n",
        "if os.path.exists(ext_data_path):\n",
        "    df = pd.read_csv(ext_data_path)\n",
        "    ext_lbls = torch.tensor(df.iloc[:, 0].values).long()\n",
        "    ext_imgs = torch.tensor(df.iloc[:, 1:].values).float().reshape(-1, 1, 28, 28) / 255.0\n",
        "    ext_imgs, ext_lbls = ext_imgs.to(device), ext_lbls.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef57be5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, imgs, lbls):\n",
        "    if model is None: return 0\n",
        "    with torch.no_grad():\n",
        "        preds = model(imgs.to(device)).argmax(1)\n",
        "        return (preds == lbls.to(device)).float().mean().item() * 100\n",
        "\n",
        "offense_vs_std = []\n",
        "offense_vs_rob = []\n",
        "l2_costs = []\n",
        "\n",
        "for name, fname, _ in model_configs:\n",
        "    path = f\"{adv_dir}/500_adv_{fname}\"\n",
        "    if not os.path.exists(path):\n",
        "        offense_vs_std.append(0); offense_vs_rob.append(0); l2_costs.append(0)\n",
        "        continue\n",
        "        \n",
        "    data = torch.load(path)\n",
        "    adv_imgs = data['adv']\n",
        "    adv_lbls = data['lbl']\n",
        "    l2_costs.append(data['avg_l2'])\n",
        "    \n",
        "    scores_std = [evaluate(zoo_models['MLP_Std'], adv_imgs, adv_lbls),\n",
        "                  evaluate(zoo_models['CNN_Std'], adv_imgs, adv_lbls)]\n",
        "    offense_vs_std.append(100 - np.mean(scores_std))\n",
        "    \n",
        "    scores_rob = [evaluate(zoo_models['MLP_Rob'], adv_imgs, adv_lbls),\n",
        "                  evaluate(zoo_models['CNN_Rob'], adv_imgs, adv_lbls)]\n",
        "    offense_vs_rob.append(100 - np.mean(scores_rob))\n",
        "\n",
        "from torchvision.models import squeezenet1_0\n",
        "class LeNet5(nn.Module): \n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5); self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(256, 120); self.fc2 = nn.Linear(120, 84); self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x)); x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x)); x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1); x = F.relu(self.fc1(x)); x = F.relu(self.fc2(x)); return self.fc3(x)\n",
        "class SqueezeNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__(); self.m = squeezenet1_0(num_classes=10); self.m.features[0] = nn.Conv2d(1,96,7,stride=2); self.m.classifier[1] = nn.Conv2d(512,10,1)\n",
        "    def forward(self, x): return self.m(x)\n",
        "\n",
        "defense_scores = []\n",
        "for _, fname, arch in model_configs:\n",
        "    m = LeNet5() if arch == 'lenet' else SqueezeNetMNIST()\n",
        "    m.load_state_dict(torch.load(f\"{base_path}/model_weights/{fname}\", map_location=device))\n",
        "    m.to(device).eval()\n",
        "    if ext_imgs is not None:\n",
        "        defense_scores.append(evaluate(m, ext_imgs, ext_lbls))\n",
        "    else:\n",
        "        defense_scores.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee6ece6",
      "metadata": {},
      "outputs": [],
      "source": [
        "names = [c[0] for c in model_configs]\n",
        "x = np.arange(len(names))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(x - width/2, offense_vs_std, width, label='vs. Standard Zoo', color='purple', alpha=0.8)\n",
        "plt.bar(x + width/2, offense_vs_rob, width, label='vs. Robust Zoo', color='orange', alpha=0.8)\n",
        "plt.xticks(x, names, rotation=15)\n",
        "plt.ylabel(\"Attack Success Rate (%)\")\n",
        "plt.title(\"Offense Score (Transferability to Unseen Models)\")\n",
        "plt.legend()\n",
        "plt.ylim(0, 100)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d35244",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, defense_scores, color='green', alpha=0.7, edgecolor='black')\n",
        "plt.xticks(x, names, rotation=15)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Defense Score (Robustness against External Attacks)\")\n",
        "plt.ylim(0, 100)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1863054",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x, l2_costs, color='gray', alpha=0.7, edgecolor='black')\n",
        "plt.xticks(x, names, rotation=15)\n",
        "plt.ylabel(\"Average L2 Norm\")\n",
        "plt.title(\"Perturbation Cost (Visual Distortion Required)\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
