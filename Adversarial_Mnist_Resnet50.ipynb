{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AywAcoMgoqlB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.utils.data as DataUtils\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Readymade data loading function\n",
        "DATA_ROOT='./MNISTData/'\n",
        "def getMNISTDataLoaders(batchSize=64, nTrain=50000, nVal=10000, nTest=10000):\n",
        "  # You can use technically use the same transform instance for all 3 sets\n",
        "  assert (60000 - nVal) == nTrain, 'nTrain + nVal must be equal to 60000'\n",
        "  trainTransform = transforms.Compose([transforms.ToTensor()])\n",
        "  valTransform = transforms.Compose([transforms.ToTensor()])\n",
        "  testTransform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  trainSet = datasets.MNIST(root=DATA_ROOT, download=True, train=True, \\\n",
        "                           transform=trainTransform)\n",
        "  valSet = datasets.MNIST(root=DATA_ROOT, download=True, train=True, \\\n",
        "                         transform=valTransform)\n",
        "  testSet = datasets.MNIST(root=DATA_ROOT, download=True, train=False, \\\n",
        "                                 transform=testTransform)\n",
        "\n",
        "  indices = np.arange(0, 60000)\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  trainSampler = SubsetRandomSampler(indices[:nTrain])\n",
        "  valSampler = SubsetRandomSampler(indices[nTrain:])\n",
        "  testSampler = SubsetRandomSampler(np.arange(0, nTest))\n",
        "\n",
        "  trainLoader = DataUtils.DataLoader(trainSet, batch_size=batchSize, \\\n",
        "                                   sampler=trainSampler)\n",
        "  valLoader = DataUtils.DataLoader(valSet, batch_size=batchSize, \\\n",
        "                                  sampler=valSampler)\n",
        "  testLoader = DataUtils.DataLoader(testSet, batch_size=batchSize, \\\n",
        "                                    sampler=testSampler)\n",
        "  return trainLoader, valLoader, testLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dyABrPSo5TH",
        "outputId": "91222d87-6106-4a9e-ed38-4965d35f7bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook will use PyTorch Device: CUDA\n"
          ]
        }
      ],
      "source": [
        "# Define the `device` PyTorch will be running on\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Notebook will use PyTorch Device: ' + device.upper())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fV9dNMKBo5rC"
      },
      "outputs": [],
      "source": [
        "# Utility Progress Bar Function\n",
        "def progress(curr, total, suffix=''):\n",
        "  bar_len = 48\n",
        "  filled = int(round(bar_len * curr / float(total)))\n",
        "  if filled == 0:\n",
        "    filled = 1\n",
        "  bar = '=' * (filled - 1) + '>' + '-' * (bar_len - filled)\n",
        "  sys.stdout.write('\\r[%s] .. %s' % (bar, suffix))\n",
        "  sys.stdout.flush()\n",
        "  if curr == total:\n",
        "    bar = bar_len * '='\n",
        "    sys.stdout.write('\\r[%s] .. %s .. Completed\\n' % (bar, suffix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4f9WG5jzpC_X"
      },
      "outputs": [],
      "source": [
        "###  Google Colab doesn't ship with advertorch and we will have to install it ourselves\n",
        "# !pip install advertorch > /dev/null\n",
        "# import advertorch\n",
        "!pip install torchattack > /dev/null\n",
        "from torchattack import PGD\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# print(advertorch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI5TV64vR8E_",
        "outputId": "dba46321-a35d-4085-b3f8-62f1eee6859e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "adv_model = models.resnet50(pretrained=False)\n",
        "adv_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "adv_model.fc = nn.Linear(2048, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D_QeGH-ypJhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e3cc78-c32d-4bcb-e422-41f103486c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 752kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.63MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.27MB/s]\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "lr = 1e-2\n",
        "step = 0\n",
        "xent_loss = nn.CrossEntropyLoss()\n",
        "adv_model = adv_model.to(device)\n",
        "adv_model.train()\n",
        "optimizer = torch.optim.SGD(adv_model.parameters(), lr=lr)\n",
        "\n",
        "train_loader, val_loader, test_loader = getMNISTDataLoaders()\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBCJhvrSpLtY",
        "outputId": "df3db365-f61d-4f59-a170-b0891c3fea55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[===============================================>] .. Batch [777/782] Epoch [10/10] Loss = 0.641\n",
            "Total training steps = 7820\n",
            "Total time taken = 3433.1333475112915\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Modified adversarial training using torchattack library.\n",
        "Now trains on both original and adversarial examples for better robustness\n",
        "while maintaining clean accuracy.\n",
        "\"\"\"\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  for j, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    \"\"\"\n",
        "    Creating the adversary:\n",
        "    -----------------------\n",
        "    Adversarial examples should be generated when model parameters are frozen.\n",
        "    This is essential for models with dropout or batch normalization.\n",
        "    \"\"\"\n",
        "    adv_model.eval()  # Freeze model parameters\n",
        "\n",
        "    \"\"\"\n",
        "    PGD Attack Parameters:\n",
        "    - eps: perturbation budget (0.3 for MNIST in [0, 1] range)\n",
        "    - steps: number of PGD iterations (7 is standard)\n",
        "    - random_start: whether to start from random perturbation (more robust)\n",
        "    \"\"\"\n",
        "    adversary = PGD(adv_model, eps=0.3, steps=7, random_start=True)\n",
        "    adv_images = adversary(images, labels)  # Generate adversarial samples\n",
        "\n",
        "    # Unfreeze model parameters for training\n",
        "    adv_model.train()\n",
        "\n",
        "    \"\"\"\n",
        "    Concatenate original and adversarial examples for mixed training.\n",
        "    This allows the model to learn robustness while maintaining clean accuracy.\n",
        "    \"\"\"\n",
        "    train_images = torch.cat([images, adv_images], dim=0)\n",
        "    train_labels = torch.cat([labels, labels], dim=0)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = adv_model(train_images)\n",
        "    loss = loss_fn(logits, train_labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if j % 8 == 0:\n",
        "      progress(j+1, len(train_loader), 'Batch [{}/{}] Epoch [{}/{}] Loss = {:.3f}'.format(j+1, len(train_loader), i+1, n_epochs, loss.item()))\n",
        "    step += 1\n",
        "\n",
        "end_time = time.time()\n",
        "print('\\nTotal training steps = {}'.format(step))\n",
        "print('Total time taken = {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-096JjMmahhX",
        "outputId": "474829ef-3492-4385-df5b-4eca20ea5e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================================] .. Batch [157/157] .. Completed\n",
            "Accuracy = 98.78%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation code - 98.92%\n",
        "correct = 0\n",
        "adv_model.eval()\n",
        "for j, (images, labels) in enumerate(test_loader):\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  logits = adv_model(images)\n",
        "  _, preds = torch.max(logits, 1)\n",
        "  correct += (preds == labels).sum().item()\n",
        "  progress(j+1, len(test_loader), 'Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
        "adv_model.train()\n",
        "print('Accuracy = {}%'.format(float(correct) * 100 / 10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1utdxvWxpOUG",
        "outputId": "7c2d235e-8caf-4e0f-98c6-ec26bd669ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[================================================] .. Batch [157/157] .. Completed\n",
            "Accuracy on FGSM adversarial samples = 50.34%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating against PGD attack - 44.44%\n",
        "adversary = PGD(adv_model, eps=0.3, steps=7, random_start=True)\n",
        "correct = 0\n",
        "adv_model.eval()\n",
        "for j, (images, labels) in enumerate(test_loader):\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "  adv_images = adversary(images, labels)  # Generate adversarial samples\n",
        "  logits = adv_model(adv_images)\n",
        "  _, preds = torch.max(logits, 1)\n",
        "  correct += (preds == labels).sum().item()\n",
        "  progress(j+1, len(test_loader), 'Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
        "adv_model.train()\n",
        "print('Accuracy on FGSM adversarial samples = {}%'.format(float(correct) * 100 / 10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGZnz-kCpQn4",
        "outputId": "e2c64f01-4f7c-4226-9248-0ed17980005e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model saved to Google Drive: adversarial_mnist/saved_models/resnet50_adv_trained.pth\n",
            "\n",
            "Google Drive structure created:\n",
            "  My Drive/\n",
            "    adversarial_mnist/\n",
            "      saved_models/\n",
            "      adversarial_examples/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directories in Google Drive\n",
        "os.makedirs('/content/drive/My Drive/adversarial_mnist/saved_models', exist_ok=True)\n",
        "os.makedirs('/content/drive/My Drive/adversarial_mnist/adversarial_examples', exist_ok=True)\n",
        "\n",
        "# Save the adversarially trained model\n",
        "torch.save(adv_model.state_dict(), '/content/drive/My Drive/adversarial_mnist/saved_models/resnet50_adv_trained.pth')\n",
        "print(\"Model saved to Google Drive: adversarial_mnist/saved_models/resnet50_adv_trained.pth\")\n",
        "\n",
        "print(\"\\nGoogle Drive structure created:\")\n",
        "print(\"  My Drive/\")\n",
        "print(\"    adversarial_mnist/\")\n",
        "print(\"      saved_models/\")\n",
        "print(\"      adversarial_examples/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0jjipEYTGVF"
      },
      "outputs": [],
      "source": [
        "import torchattack\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "adv_model.eval()\n",
        "\n",
        "# We'll loop through the test set until we collect 25 fooling examples\n",
        "fooling_examples = []\n",
        "fooling_labels = []\n",
        "fooling_perturbations = []\n",
        "fooled_as_labels = []\n",
        "examples_found = 0\n",
        "target_count = 25\n",
        "\n",
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "    if examples_found >= target_count:\n",
        "        break\n",
        "\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Generate adversarial examples\n",
        "    adversary = torchattack.PGD(adv_model, eps=0.3, steps=7, random_start=True)\n",
        "    adv_images = adversary(images, labels)\n",
        "\n",
        "    # Get model predictions on adversarial examples\n",
        "    with torch.no_grad():\n",
        "        logits = adv_model(adv_images)\n",
        "        _, preds = torch.max(logits, 1)\n",
        "\n",
        "    # Find which ones actually fool the model (prediction != true label)\n",
        "    fooled_mask = (preds != labels)\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "        if examples_found >= target_count:\n",
        "            break\n",
        "\n",
        "        if fooled_mask[i].item():  # Only save if it fooled the model\n",
        "            clean_img = images[i].cpu().detach()\n",
        "            adv_img = adv_images[i].cpu().detach()\n",
        "            perturbation = (adv_img - clean_img).detach()\n",
        "\n",
        "            fooling_examples.append(adv_img)\n",
        "            fooling_labels.append(labels[i].item())\n",
        "            fooling_perturbations.append(perturbation)\n",
        "            fooled_as_labels.append(preds[i].item())\n",
        "\n",
        "            # Save individual examples as tensors to Google Drive\n",
        "            torch.save({\n",
        "                'clean': clean_img,\n",
        "                'adversarial': adv_img,\n",
        "                'perturbation': perturbation,\n",
        "                'true_label': labels[i].item(),\n",
        "                'fooled_label': preds[i].item()\n",
        "            }, f'/content/drive/My Drive/adversarial_mnist/adversarial_examples/fooling_example_{examples_found}_resnet50.pth')\n",
        "\n",
        "            # Save PNG visualizations\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
        "\n",
        "            # Clean image\n",
        "            axes[0].imshow(clean_img.squeeze().numpy(), cmap='gray')\n",
        "            axes[0].set_title(f'Clean\\nTrue Label: {labels[i].item()}')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # Adversarial image\n",
        "            axes[1].imshow(adv_img.squeeze().numpy(), cmap='gray')\n",
        "            axes[1].set_title(f'Adversarial\\nFooled as: {preds[i].item()}')\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            # Perturbation (amplified for visibility)\n",
        "            perturbation_vis = perturbation.squeeze().abs() * 10  # Scale for visibility\n",
        "            axes[2].imshow(perturbation_vis.numpy(), cmap='hot')\n",
        "            axes[2].set_title(f'Perturbation\\n(amplified)')\n",
        "            axes[2].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'/content/drive/My Drive/adversarial_mnist/adversarial_examples/fooling_example_{examples_found}_resnet50.png',\n",
        "                        dpi=100, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            examples_found += 1\n",
        "            print(f\"Found {examples_found}/25 fooling examples\")\n",
        "\n",
        "# Save all fooling examples as a single tensor file to Google Drive\n",
        "torch.save({\n",
        "    'adversarial_examples': torch.stack(fooling_examples),\n",
        "    'true_labels': fooling_labels,\n",
        "    'fooled_as_labels': fooled_as_labels,\n",
        "    'perturbations': torch.stack(fooling_perturbations)\n",
        "}, '/content/drive/My Drive/adversarial_mnist/adversarial_examples/all_fooling_examples_resnet50.pth')\n",
        "\n",
        "print(f\"\\nTotal fooling examples found: {examples_found}\")\n",
        "print(\"All files saved to Google Drive: My Drive/adversarial_mnist/\")\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"  - fooling_example_X.pth (tensor data)\")\n",
        "print(\"  - fooling_example_X.png (visualization)\")\n",
        "print(\"  - all_fooling_examples.pth (all examples combined)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lBCNL9ibHsp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}