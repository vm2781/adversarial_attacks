{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e7ec623b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ec623b",
        "outputId": "92089892-ecd3-4a1c-8aab-058677426af8",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import squeezenet1_0, resnet18\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchattack"
      ],
      "metadata": {
        "id": "p2MJKc4krisU",
        "outputId": "1671b811-b2af-4d51-f50b-fa02fd0e68a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p2MJKc4krisU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchattack in /usr/local/lib/python3.12/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from torchattack) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from torchattack) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from torchattack) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->torchattack) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.14.0->torchattack) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->torchattack) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->torchattack) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchattack import PGD"
      ],
      "metadata": {
        "id": "VG5s06qVrj5-"
      },
      "id": "VG5s06qVrj5-",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8bbaccaa",
      "metadata": {
        "id": "8bbaccaa",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5); self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(256, 120); self.fc2 = nn.Linear(120, 84); self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x)); x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x)); x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1); x = F.relu(self.fc1(x)); x = F.relu(self.fc2(x)); return self.fc3(x)\n",
        "\n",
        "class SqueezeNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SqueezeNetMNIST, self).__init__()\n",
        "        self.model = squeezenet1_0(num_classes=10)\n",
        "        self.model.classifier[1] = nn.Conv2d(512, 10, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 1: x = x.repeat(1, 3, 1, 1)\n",
        "        return self.model(x)\n",
        "\n",
        "class ResNet18MNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18MNIST, self).__init__()\n",
        "        self.model = resnet18(num_classes=10)\n",
        "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(28*28, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.linear(x)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "class ConvNetTiny(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetTiny, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
        "        self.fc1 = nn.Linear(8 * 13 * 13, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "class ConvNetWide(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetWide, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "class ConvNetDeep(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetDeep, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Linear(32 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class MiniVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MiniVGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Linear(64 * 3 * 3, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool):\n",
        "        super(InceptionModule, self).__init__()\n",
        "        self.branch1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red_3x3, kernel_size=1),\n",
        "            nn.Conv2d(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red_5x5, kernel_size=1),\n",
        "            nn.Conv2d(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, out_pool, kernel_size=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
        "\n",
        "class MiniGoogLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MiniGoogLeNet, self).__init__()\n",
        "        self.pre_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.inception = InceptionModule(64, 16, 32, 24, 8, 8, 16)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pre_layers(x)\n",
        "        x = self.inception(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class MiniDenseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MiniDenseNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(16 * 14 * 14, 10)\n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.conv1(x))\n",
        "        out2 = F.relu(self.conv2(out1))\n",
        "        c2 = torch.cat([out1, out2], 1)\n",
        "        out3 = F.relu(self.conv3(c2))\n",
        "        x = self.pool(out3)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "base_path = '/content/drive/My Drive/adversarial_mnist'\n",
        "weights_dir = f'{base_path}/model_weights'\n",
        "adv_dir = f'{base_path}/large_adversarial_examples'\n",
        "os.makedirs(weights_dir, exist_ok=True)\n",
        "os.makedirs(adv_dir, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a4181859",
      "metadata": {
        "id": "a4181859",
        "vscode": {
          "languageId": "plaintext"
        },
        "outputId": "97c88678-72e9-425e-9da9-a91f79f62444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total models in zoo: 24\n"
          ]
        }
      ],
      "source": [
        "model_configs = []\n",
        "architectures = [\n",
        "    ('Linear', LinearModel),\n",
        "    ('MLP', MLP),\n",
        "    ('ConvTiny', ConvNetTiny),\n",
        "    ('Simple', SimpleCNN),\n",
        "    ('ConvWide', ConvNetWide),\n",
        "    ('ConvDeep', ConvNetDeep),\n",
        "    ('LeNet', LeNet5),\n",
        "    ('MiniVGG', MiniVGG),\n",
        "    ('Squeeze', SqueezeNetMNIST),\n",
        "    ('MiniInception', MiniGoogLeNet),\n",
        "    ('MiniDense', MiniDenseNet),\n",
        "    ('ResNet', ResNet18MNIST)\n",
        "]\n",
        "\n",
        "for seed in range(2):\n",
        "    for name, arch_cls in architectures:\n",
        "        model_name = f\"{name}_s{seed}\"\n",
        "        model_file = f\"{name.lower()}_s{seed}.pth\"\n",
        "        model_configs.append((model_name, model_file, arch_cls, seed))\n",
        "\n",
        "print(f\"Total models in zoo: {len(model_configs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "41e8c54d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e8c54d",
        "outputId": "d0cc4638-e09f-4402-b999-29f2b1e2ba50",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear_s0...\n",
            "Saved Linear_s0\n",
            "Training MLP_s0...\n",
            "Saved MLP_s0\n",
            "Training ConvTiny_s0...\n",
            "Saved ConvTiny_s0\n",
            "Training Simple_s0...\n",
            "Saved Simple_s0\n",
            "Training ConvWide_s0...\n",
            "Saved ConvWide_s0\n",
            "Training ConvDeep_s0...\n",
            "Saved ConvDeep_s0\n",
            "Training LeNet_s0...\n",
            "Saved LeNet_s0\n",
            "Training MiniVGG_s0...\n",
            "Saved MiniVGG_s0\n",
            "Training Squeeze_s0...\n",
            "Saved Squeeze_s0\n",
            "Training MiniInception_s0...\n",
            "Saved MiniInception_s0\n",
            "Training MiniDense_s0...\n",
            "Saved MiniDense_s0\n",
            "Training ResNet_s0...\n",
            "Saved ResNet_s0\n",
            "Training Linear_s1...\n",
            "Saved Linear_s1\n",
            "Training MLP_s1...\n",
            "Saved MLP_s1\n",
            "Training ConvTiny_s1...\n",
            "Saved ConvTiny_s1\n",
            "Training Simple_s1...\n",
            "Saved Simple_s1\n",
            "Training ConvWide_s1...\n",
            "Saved ConvWide_s1\n",
            "Training ConvDeep_s1...\n",
            "Saved ConvDeep_s1\n",
            "Training LeNet_s1...\n",
            "Saved LeNet_s1\n",
            "Training MiniVGG_s1...\n",
            "Saved MiniVGG_s1\n",
            "Training Squeeze_s1...\n",
            "Saved Squeeze_s1\n",
            "Training MiniInception_s1...\n",
            "Saved MiniInception_s1\n",
            "Training MiniDense_s1...\n",
            "Saved MiniDense_s1\n",
            "Training ResNet_s1...\n",
            "Saved ResNet_s1\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, loader, epochs=10):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "for name, fname, arch_cls, seed in model_configs:\n",
        "    path = f\"{weights_dir}/{fname}\"\n",
        "    print(f\"Training {name}...\")\n",
        "    set_seed(seed)\n",
        "    model = arch_cls().to(device)\n",
        "    train_model(model, train_loader)\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Saved {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_clean(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return 100 * correct / total\n",
        "\n",
        "for name, fname, arch_cls, seed in model_configs:\n",
        "    path = f\"{weights_dir}/{fname}\"\n",
        "    save_path = f\"{adv_dir}/500_adv_{fname}\"\n",
        "\n",
        "    print(f\"Generating adversarial data for {name}...\")\n",
        "    model = arch_cls().to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    acc = evaluate_clean(model, test_loader)\n",
        "\n",
        "    attack = PGD(model, eps=0.3, alpha=0.01, steps=40, random_start=True)\n",
        "\n",
        "    adv_images = []\n",
        "    clean_images = []\n",
        "    labels = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        if len(adv_images) * test_loader.batch_size >= 500:\n",
        "            break\n",
        "\n",
        "        adv = attack(data, target)\n",
        "        adv_images.append(adv.cpu())\n",
        "        clean_images.append(data.cpu())\n",
        "        labels.append(target.cpu())\n",
        "\n",
        "    adv_images = torch.cat(adv_images)[:500]\n",
        "    clean_images = torch.cat(clean_images)[:500]\n",
        "    labels = torch.cat(labels)[:500]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(adv_images.to(device)).argmax(dim=1)\n",
        "        rob_acc = (preds == labels.to(device)).float().mean().item() * 100\n",
        "\n",
        "    torch.save({\n",
        "        'clean': clean_images,\n",
        "        'adv': adv_images,\n",
        "        'lbl': labels,\n",
        "        'score_clean': acc,\n",
        "        'score_robust': rob_acc\n",
        "    }, save_path)\n",
        "    print(f\"Saved dataset for {name} (Clean: {acc:.1f}%, Robust: {rob_acc:.1f}%) \")"
      ],
      "metadata": {
        "id": "TxEm5FMTuIk4",
        "outputId": "463d862f-f368-423b-eb1d-b70a68859563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TxEm5FMTuIk4",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating adversarial data for Linear_s0...\n",
            "Saved dataset for Linear_s0 (Clean: 92.7%, Robust: 0.0%) \n",
            "Generating adversarial data for MLP_s0...\n",
            "Saved dataset for MLP_s0 (Clean: 97.9%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvTiny_s0...\n",
            "Saved dataset for ConvTiny_s0 (Clean: 97.5%, Robust: 0.0%) \n",
            "Generating adversarial data for Simple_s0...\n",
            "Saved dataset for Simple_s0 (Clean: 98.8%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvWide_s0...\n",
            "Saved dataset for ConvWide_s0 (Clean: 99.0%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvDeep_s0...\n",
            "Saved dataset for ConvDeep_s0 (Clean: 99.2%, Robust: 0.0%) \n",
            "Generating adversarial data for LeNet_s0...\n",
            "Saved dataset for LeNet_s0 (Clean: 98.8%, Robust: 0.0%) \n",
            "Generating adversarial data for MiniVGG_s0...\n",
            "Saved dataset for MiniVGG_s0 (Clean: 99.2%, Robust: 0.0%) \n",
            "Generating adversarial data for Squeeze_s0...\n",
            "Saved dataset for Squeeze_s0 (Clean: 88.5%, Robust: 9.8%) \n",
            "Generating adversarial data for MiniInception_s0...\n",
            "Saved dataset for MiniInception_s0 (Clean: 81.3%, Robust: 0.0%) \n",
            "Generating adversarial data for MiniDense_s0...\n",
            "Saved dataset for MiniDense_s0 (Clean: 98.9%, Robust: 0.0%) \n",
            "Generating adversarial data for ResNet_s0...\n",
            "Saved dataset for ResNet_s0 (Clean: 99.3%, Robust: 0.0%) \n",
            "Generating adversarial data for Linear_s1...\n",
            "Saved dataset for Linear_s1 (Clean: 92.6%, Robust: 0.0%) \n",
            "Generating adversarial data for MLP_s1...\n",
            "Saved dataset for MLP_s1 (Clean: 97.9%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvTiny_s1...\n",
            "Saved dataset for ConvTiny_s1 (Clean: 97.6%, Robust: 0.0%) \n",
            "Generating adversarial data for Simple_s1...\n",
            "Saved dataset for Simple_s1 (Clean: 98.7%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvWide_s1...\n",
            "Saved dataset for ConvWide_s1 (Clean: 99.0%, Robust: 0.0%) \n",
            "Generating adversarial data for ConvDeep_s1...\n",
            "Saved dataset for ConvDeep_s1 (Clean: 99.1%, Robust: 0.0%) \n",
            "Generating adversarial data for LeNet_s1...\n",
            "Saved dataset for LeNet_s1 (Clean: 99.0%, Robust: 0.0%) \n",
            "Generating adversarial data for MiniVGG_s1...\n",
            "Saved dataset for MiniVGG_s1 (Clean: 99.2%, Robust: 0.0%) \n",
            "Generating adversarial data for Squeeze_s1...\n",
            "Saved dataset for Squeeze_s1 (Clean: 89.0%, Robust: 18.8%) \n",
            "Generating adversarial data for MiniInception_s1...\n",
            "Saved dataset for MiniInception_s1 (Clean: 81.1%, Robust: 0.0%) \n",
            "Generating adversarial data for MiniDense_s1...\n",
            "Saved dataset for MiniDense_s1 (Clean: 98.5%, Robust: 0.0%) \n",
            "Generating adversarial data for ResNet_s1...\n",
            "Saved dataset for ResNet_s1 (Clean: 99.1%, Robust: 0.0%) \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}