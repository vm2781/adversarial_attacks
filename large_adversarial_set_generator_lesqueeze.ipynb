{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ec623b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ec623b",
        "outputId": "20c43fb9-7dc5-4d54-e116-03f612b5a1b5",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install torchattack > /dev/null\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as DataUtils\n",
        "from torchvision.models import squeezenet1_0\n",
        "from torchattack import PGD\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbaccaa",
      "metadata": {
        "id": "8bbaccaa",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=0)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class SqueezeNetMNIST(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SqueezeNetMNIST, self).__init__()\n",
        "        self.model = squeezenet1_0(num_classes=10)\n",
        "        self.model.features[0] = nn.Conv2d(1, 96, kernel_size=7, stride=2)\n",
        "        self.model.classifier[1] = nn.Conv2d(512, 10, kernel_size=1)\n",
        "    def forward(self, x): return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4181859",
      "metadata": {
        "id": "a4181859",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def get_dataloader(batch_size=64):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    dset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    return DataUtils.DataLoader(dset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "base_path = '/content/drive/My Drive/adversarial_mnist'\n",
        "dirs = {\n",
        "    'weights': f'{base_path}/model_weights',\n",
        "    'output': f'{base_path}/large_adversarial_examples',\n",
        "}\n",
        "for d in dirs.values(): os.makedirs(d, exist_ok=True)\n",
        "\n",
        "target_models = [\n",
        "    ('lenet', 'lenet.pth'),\n",
        "    ('lenet', 'lenet_robust.pth'),\n",
        "    ('squeezenet', 'squeezenet.pth'),\n",
        "    ('squeezenet', 'squeezenet_robust.pth')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e8c54d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e8c54d",
        "outputId": "166b05ce-3621-4a6a-cfbe-cbebe47ce58e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing resnet18_pgd_robust.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 5.0648\n",
            "\n",
            "Processing resnet18_standard_trained.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.4346\n",
            "\n",
            "Processing resnet50_pgd_robust.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.8592\n",
            "\n",
            "Processing resnet50_standard_trained.pth...\n",
            "  Saved 500 examples\n",
            "  Average L2 Perturbation: 4.2504\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loader = get_dataloader(batch_size=32)\n",
        "\n",
        "for arch, filename in target_models:\n",
        "    print(f\"Processing Source: {filename}...\")\n",
        "    model = LeNet5().to(device) if 'lenet' in arch else SqueezeNetMNIST().to(device)\n",
        "    \n",
        "    path = f\"{dirs['weights']}/{filename}\"\n",
        "    if os.path.exists(path):\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "    else:\n",
        "        print(f\"  [!] Missing weights: {path}\")\n",
        "        continue\n",
        "        \n",
        "    model.eval()\n",
        "    adversary = PGD(model, eps=0.3, steps=40, random_start=True)\n",
        "    \n",
        "    examples, true_lbls, dists = [], [], []\n",
        "    \n",
        "    for img, lbl in loader:\n",
        "        if len(examples) >= 500: break\n",
        "        img, lbl = img.to(device), lbl.to(device)\n",
        "        adv = adversary(img, lbl)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            pred = model(adv).argmax(1)\n",
        "        \n",
        "        batch_fool = (pred != lbl)\n",
        "        if batch_fool.sum() > 0:\n",
        "            diff = (adv - img).reshape(len(img), -1)\n",
        "            l2 = torch.norm(diff, p=2, dim=1)\n",
        "            examples.append(adv[batch_fool].cpu())\n",
        "            true_lbls.append(lbl[batch_fool].cpu())\n",
        "            dists.append(l2[batch_fool].cpu())\n",
        "\n",
        "    if examples:\n",
        "        avg_dist = torch.cat(dists).mean().item()\n",
        "        torch.save({\n",
        "            'adv': torch.cat(examples)[:500], \n",
        "            'lbl': torch.cat(true_lbls)[:500],\n",
        "            'avg_l2': avg_dist\n",
        "        }, f\"{dirs['output']}/500_adv_{filename}\")\n",
        "        print(f\"  -> Saved {len(examples)} batches.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
